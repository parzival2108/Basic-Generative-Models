{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3c1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bcff4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d93cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bceba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de3cc2e",
   "metadata": {},
   "source": [
    "# Hyperparamater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93036470",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "original_dim = 784\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f8994",
   "metadata": {},
   "source": [
    "# Building the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c09e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(original_dim,))\n",
    "x1 = Dense(original_dim//2, activation='relu')(x)\n",
    "x2 = Dense(original_dim//3, activation='relu')(x1)\n",
    "h = Dense(intermediate_dim, activation='relu')(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e6a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c77ca92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d3727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=K.shape(z_mean))\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff23aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2db32f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "dc1 = Dense(original_dim//3, activation='relu')\n",
    "dc2 = Dense(original_dim//2, activation='relu')\n",
    "\n",
    "h_decoded = decoder_h(z)\n",
    "h_decoded = dc1(h_decoded)\n",
    "h_decoded = dc2(h_decoded)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb8d5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xent_loss = K.sum(K.binary_crossentropy(x, x_decoded_mean), axis=-1)\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c51ce89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 392)          307720      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 261)          102573      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          67072       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            514         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 2)            514         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 2)            0           ['dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 256)          768         ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 261)          67077       ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 392)          102704      ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 784)          308112      ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 2)           0           ['dense_4[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.square (TFOpLambda)    (None, 2)            0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 2)            0           ['tf.__operators__.add[0][0]',   \n",
      "                                                                  'tf.math.square[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.exp (TFOpLambda)       (None, 2)            0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 2)           0           ['tf.math.subtract[0][0]',       \n",
      " )                                                                'tf.math.exp[0][0]']            \n",
      "                                                                                                  \n",
      " tf.keras.backend.binary_crosse  (None, 784)         0           ['input_1[0][0]',                \n",
      " ntropy (TFOpLambda)                                              'dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None,)             0           ['tf.math.subtract_1[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None,)             0           ['tf.keras.backend.binary_crossen\n",
      " )                                                               tropy[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.math.reduce_sum_1[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None,)             0           ['tf.math.reduce_sum[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.__operators__.add_1[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 957,054\n",
      "Trainable params: 957,054\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae = Model(x, x_decoded_mean)\n",
    "vae.add_loss(vae_loss)\n",
    "optimizer = tf.keras.optimizers.Adam(amsgrad=True)\n",
    "vae.compile(optimizer=optimizer )\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3d5df85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc27c2b3290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc27c2b3290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1867/1875 [============================>.] - ETA: 0s - loss: 169.3777WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc27bd023b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc27bd023b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 169.3297 - val_loss: 155.8456\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 152.1851 - val_loss: 149.3974\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 147.7733 - val_loss: 146.4033\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 145.5940 - val_loss: 145.4094\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 143.9995 - val_loss: 144.3836\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 143.1801 - val_loss: 141.9308\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 143.0768 - val_loss: 142.0176\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 142.0599 - val_loss: 140.8004\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 141.4260 - val_loss: 141.1045\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 141.2336 - val_loss: 143.0383\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 140.6788 - val_loss: 140.5084\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 140.2268 - val_loss: 140.5549\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 139.9792 - val_loss: 141.0423\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 139.6334 - val_loss: 139.8246\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 139.3052 - val_loss: 139.6993\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 138.7495 - val_loss: 138.7151\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 138.6663 - val_loss: 140.4338\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 139.4935 - val_loss: 138.8628\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 138.8913 - val_loss: 139.5808\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 138.4223 - val_loss: 139.3656\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 137.9587 - val_loss: 139.0823\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 138.3737 - val_loss: 138.9639\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 137.8384 - val_loss: 138.8140\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 137.7318 - val_loss: 137.5465\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 137.4226 - val_loss: 137.9361\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 137.2710 - val_loss: 137.8469\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 136.9412 - val_loss: 138.2287\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 137.0808 - val_loss: 138.1507\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 136.9781 - val_loss: 137.9500\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 137.7613 - val_loss: 137.8886\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 137.0365 - val_loss: 137.9727\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 137.1919 - val_loss: 138.0594\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 137.0860 - val_loss: 136.6387\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 137.0639 - val_loss: 137.1093\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 136.5314 - val_loss: 139.4752\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 138.0719 - val_loss: 137.9014\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 136.8655 - val_loss: 137.2831\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 135.9985 - val_loss: 136.4560\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 136.0010 - val_loss: 137.5020\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 135.7656 - val_loss: 136.6091\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 135.9342 - val_loss: 136.7098\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 135.8616 - val_loss: 137.4385\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 136.2471 - val_loss: 136.9692\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 137.0259 - val_loss: 137.5170\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 136.6251 - val_loss: 137.3217\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 22s 11ms/step - loss: 136.8109 - val_loss: 136.9487\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 136.3879 - val_loss: 136.7166\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 135.8570 - val_loss: 136.5336\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 136.1413 - val_loss: 137.3291\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 136.0742 - val_loss: 137.2154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc27c0a8050>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(x, z_mean)\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.savefig(\"contents/encoding.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc762f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_h_decoded = dc1(_h_decoded)\n",
    "_h_decoded = dc2(_h_decoded)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae276423",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15  \n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]]) * 1.0\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.savefig('contents/mapping.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
